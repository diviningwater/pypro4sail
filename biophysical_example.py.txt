from pathlib import Path
import multiprocessing as mp
import numpy as np
import pandas as pd
import datetime as dt
from osgeo import gdal
import Py6S as sixs
from pypro4sail import machine_learning_regression as inv
from pyTSEB import meteo_utils as met
from sklearnex import patch_sklearn
patch_sklearn()
from sklearn.ensemble import RandomForestRegressor as rf_sklearn
import logging

lockutils.set_defaults(lock_path=Path.home() / "temp")
log = logging.getLogger(__name__)
AOT_SCALE = 1e3
BOA_SCALE = 1e4
VZN_SCALE = 1e2
WVP_SCALE = 1e3

S2_BANDS = ["B02", "B03", "B04", "B05", "B06",
            "B07", "B08", "B8A", "B11", "B12"]

S3_BANDS = ['O2', 'O3', 'O4', 'O5', 'O6', 
            'O7', 'O8', 'O9', 'O10', 'O11',
            'O12', 'O16', 'O17', 'O18', 'O21',
            'S5', 'S6']

LND_BANDS = {5: ["B1", "B2", "B3", "B4", "B5", "B7"],
             7: ["B1", "B2", "B3", "B4", "B5", "B7"],
             8: ["B2", "B3", "B4", "B5", "B6", "B7"],
             9: ["B2", "B3", "B4", "B5", "B6", "B7"]
             }

OBJ_PARAM_NAMES = ["Cab", "Car", "Cm", "Cw", "Ant", "Cbrown",
                   "LAI", "leaf_angle"]

LOCAL_OVERPASS_TIME = 10.5

DEFAULT_AOD = 0.1
DEFAULT_WVP = 1.0

# Path to the pyPro4SAIL soil library and SRF library
SOIL_LIBRARY = Path(inv.__file__).parent / "spectra" / "soil_spectral_library"
SRF_LIBRARY = Path(inv.__file__).parent / "spectra" / "sensor_response_functions"
ALBEDO_LIBRARY = Path(__file__).absolute().parent / "narrow2broadband"

WLS_SIM = np.arange(400, 2501)


def get_diffuse_radiation_6S(aot, wvp, sza, saa, date,
                             altitude=0.1, wls_step=10, n_jobs=None):

    s = sixs.SixS()
    s.atmos_profile = sixs.AtmosProfile.PredefinedType(
                            sixs.AtmosProfile.MidlatitudeSummer)

    s.aeroprofile = sixs.AeroProfile.PredefinedType(
                            sixs.AeroProfile.Continental)
    
    s.ground_reflectance = sixs.GroundReflectance.HomogeneousLambertian(0)

    if np.isfinite(wvp) and wvp > 0:
        s.atmos_profile = sixs.AtmosProfile.UserWaterAndOzone(wvp, 0.9)
    
    if np.isfinite(aot) and aot > 0:
        s.aot550 = aot

    s.geometry.solar_z = sza
    s.geometry.solar_a = saa
    s.geometry.view_z = 0
    s.geometry.view_a = 0
    s.geometry.day = date.day
    s.geometry.month = date.month

    s.altitudes.set_target_custom_altitude(altitude)
    s.wavelength = sixs.Wavelength(0.4, 2.5)

    wls = np.arange(400, 2501)
    wls_sim = np.arange(400, 2501, wls_step)

    wv, res = sixs.SixSHelpers.Wavelengths.run_wavelengths(s,
                                                           wls_sim / 1000.,
                                                           verbose=False,
                                                           n=n_jobs)
    
    eg_d = np.array(sixs.SixSHelpers.Wavelengths.extract_output(res, 
                                                    'diffuse_solar_irradiance'))
    
    eg_s = np.array(sixs.SixSHelpers.Wavelengths.extract_output(res, 
                                                    'direct_solar_irradiance'))
    
    eg_d = np.maximum(eg_d, 0)
    eg_s = np.maximum(eg_s, 0)
    skyl = np.full_like(wls, np.nan, dtype=np.float64)
    # Fill the diffuse values into a full wavelenght array
    valid = np.in1d(wls, wls_sim, assume_unique=True)
    skyl[valid] = eg_d / (eg_d + eg_s)
    # Fill nans by linear interpolation
    nans, x = np.isnan(skyl), lambda z: z.nonzero()[0]
    skyl[nans] = np.interp(x(nans), x(~nans), skyl[~nans])    
    
    return skyl


def build_soil_database(soil_albedo_factor,
                        soil_library=SOIL_LIBRARY):

    soil_library = Path(soil_library)
    n_simulations = np.size(soil_albedo_factor)
    soil_files = list(soil_library.glob('jhu.*spectrum.txt'))
    n_soils = len(soil_files)
    soil_spectrum = []
    for soil_file in soil_files:
        r = np.genfromtxt(soil_file)
        soil_spectrum.append(r[:, 1])

    multiplier = int(np.ceil(float(n_simulations / n_soils)))
    soil_spectrum = np.asarray(soil_spectrum * multiplier)
    soil_spectrum = soil_spectrum[:n_simulations]
    soil_spectrum = soil_spectrum * soil_albedo_factor.reshape(-1, 1)
    soil_spectrum = np.clip(soil_spectrum, 0, 1)
    soil_spectrum = soil_spectrum.T
    return soil_spectrum


def force_biophysical(boa_file,
                      vzn_file,
                      aot_file,
                      wvp_file,
                      qai_file,
                      output_folder,
                      n_simulations=40000,
                      n_jobs=1):
    """Creates biophysical traits from Sentinel-2 L2A FORCE

    Parameters
    ----------
    boa_file : str or Path object
        Path to the BOA l2a file generated by FORCE
    vzn_file : str or Path object
        Path to the VZN l2a file generated by FORCE
    aot_file : str or Path object
        Path to the AOT l2a file generated by FORCE
    wvp_file : str or Path object
        Path to the VWP l2a file generated by FORCE
    qai_file : str or Path object
        Path to the QAI l2a file generated by FORCE
    output_folder : str or Path object
        Path to the folder where the biophysical products will be saved
    n_simulations : int, optional
        Number of PROSPECT-D + 4AIL simulations
    n_jobs : int, optional
        Number of CPUs used during parallel processing

    Returns
    -------
    None
    """
    start_time = dt.datetime.today()
    scene_name = boa_file.stem
    params_orig = inv.build_prosail_database(n_simulations,
                                             distribution=inv.SALTELLI_DIST)

    scikit_regressor_opts = {"n_estimators": 100,
                             "min_samples_leaf": 1,
                             "n_jobs": n_jobs}

    log.info('Reading Sentinel ancillary information')
    date, level, satellite, product = scene_name.split("_")
    scene = f"{date}_{level}_{satellite}"
    output_name = f"{scene}_MASK.tif"
    mask_file = boa_file.parent / output_name
    if not mask_file.exists():
        log.info(f"Binary mask for {boa_file} not found")
        valid = cm.s2l2a_mask(qai_file)
    else:
        log.info(f"Reading binary mask from {mask_file}")
        valid = get_raster_data(mask_file).astype(bool)
    
    date_obj = dt.datetime.strptime(date, "%Y%m%d")
    prj, gt, _, _, _, center, *_ = raster_info(qai_file)
    dims = valid.shape
    if not np.any(valid):
        log.info(f'Print filing NANs to empty Sentinel image')
        biophysical_nan(scene, output_folder, dims, gt, prj)
        elapsed = (dt.datetime.today() - start_time).total_seconds()
        log.info(f"Finished in {elapsed/60:.1f} minutes")
        return

    # Get Day of the Year
    doy = int(date_obj.strftime("%j"))
    # Try to get overpass time from metadata
    dec_time = overpass_time_from_band_md(boa_file)
    if isinstance(dec_time, type(None)):
        stdlon = center[0]
        dec_time = LOCAL_OVERPASS_TIME
        log.info(f'Overpass time not found, assuming overpass'
                 f'at {dec_time} local time')
    else:
        stdlon = 0.
        log.info(f'Overpass time at {dec_time} GMT')

    # Get Solar angles
    sza, saa = met.calc_sun_angles(center[1],
                                   center[0], 
                                   stdlon,
                                   doy, 
                                   dec_time)

    sza, saa = map(float, [sza, saa])
    log.info(f'Getting average VZA')
    try:
        vza = get_raster_data(vzn_file)
        vza = np.nanmean(vza[valid]) / VZN_SCALE

    except:
        vza = 0

    log.info(f"Getting average AOT")
    try:
        aot = get_raster_data(aot_file)
        aot = np.nanmean(aot[valid]) / AOT_SCALE
    
    except:
        aot = DEFAULT_AOD

    log.info(f"Getting average WVP")
    try:
        wvp = get_raster_data(wvp_file)
        wvp = np.nanmean(wvp[valid]) / WVP_SCALE

    except:
        wvp = DEFAULT_WVP

    log.info(f"Running 6S for estimation of diffuse/direct irradiance")
    skyl = get_diffuse_radiation_6S(aot, wvp, sza, saa, date_obj,
                                    altitude=0.1)

    # Stack spectral bands
    srf = []
    srf_file = SRF_LIBRARY / f'Sentinel{satellite[-2:]}.txt'
    srfs = np.genfromtxt(srf_file, dtype=None, names=True)
    for band in S2_BANDS:
        srf.append(srfs[band])

    log.info(f"Builing standard soil database")
    soil_spectrum = build_soil_database(params_orig["bs"])
    log.info(f"Building {np.size(params_orig['bs'])}" 
             f"PROSPECTD+4SAIL simulations")
    if "fAPAR" in OBJ_PARAM_NAMES or "fIPAR" in OBJ_PARAM_NAMES:
        calc_fapar = True
    else:
        calc_fapar = False
    if n_jobs <= 1:
        rho_canopy_vec, params = inv.simulate_prosail_lut(params_orig,
                                                          WLS_SIM,
                                                          soil_spectrum,
                                                          skyl=skyl,
                                                          sza=sza,
                                                          vza=vza,
                                                          psi=0,
                                                          srf=srf,
                                                          outfile=None,
                                                          calc_FAPAR=calc_fapar,
                                                          reduce_4sail=True)

    else:
        rho_canopy_vec, params = inv.simulate_prosail_lut_parallel(
            n_jobs,
            params_orig,
            WLS_SIM,
            soil_spectrum,
            skyl=skyl,
            sza=sza,
            vza=vza,
            psi=0,
            srf=srf,
            outfile=None,
            calc_FAPAR=calc_fapar,
            reduce_4sail=True)

    log.info(f"Training Random forest for {','.join(OBJ_PARAM_NAMES)}")
    params = pd.DataFrame(params)
    reg = rf_sklearn(**scikit_regressor_opts)
    # Apply model to S2 image
    image_array = get_raster_data(boa_file)    
    valid = np.ravel(valid)
    image_array = image_array.reshape((image_array.shape[0], -1)).T
    image_array = image_array[valid] / BOA_SCALE
    for i, param in enumerate(OBJ_PARAM_NAMES):
        log.info(f'Applying {param} regression model to Sentinel image')
        output = np.full(np.size(valid), np.nan)
        reg = reg.fit(rho_canopy_vec, params[param])
        output[valid] = reg.predict(image_array)
        output = output.reshape(dims)
        if param == 'fAPAR' or param == 'fIPAR':
            min_value = 0
            max_value = 1
        else:
            min_value = inv.prosail_bounds[param][0]
            max_value = inv.prosail_bounds[param][1]

        output = np.clip(output, min_value, max_value)
        output_name = f"{scene}_{param.upper()}.tif"
        output_file = output_folder / output_name
        log.info(f"Saving {param} in {output_file}")
        save_image(output, gt, prj, output_file)
        del output

    del reg, rho_canopy_vec, params
    # Narrowband to Broadban reflectance
    platform = f'Sentinel{satellite[-2:]}'
    rho_par = np.full(dims, np.nan)
    rho_nir = np.full(dims, np.nan)
    valid = valid.reshape(dims)
    rho_par[valid], rho_nir[valid] = broadband_reflectance(image_array.T,
                                                           platform)[:2]

    output_file = output_folder / f"{scene}_RHO-PAR.tif"
    save_image(rho_par, gt, prj, output_file)
    del rho_par
    output_file = output_folder / f"{scene}_RHO-NIR.tif"
    save_image(rho_nir, gt, prj, output_file)
    del rho_nir

    del image_array, valid
    elapsed = (dt.datetime.today() - start_time).total_seconds()
    log.info(f"Finished in {elapsed/60:.1f} minutes")


def get_raster_data(input_file_path, bands=None):
    """
    Helper to read a GDAL image file

    Parameters
    ----------
    input_file_path : str of Path object
        Path to the input GDAL image file

    Returns
    -------
    array : 2D array
        Output numpy array
    """
    fid = gdal.Open(str(input_file_path), gdal.GA_ReadOnly)
    if isinstance(bands, type(None)):
        bands = range(1, fid.RasterCount + 1)
    array = []
    for band in bands:
        array.append(fid.GetRasterBand(band).ReadAsArray())
    del fid
    array = np.squeeze(np.array(array))
    return array


def raster_info(input_file_path):

    fid = gdal.Open(str(input_file_path), gdal.GA_ReadOnly)
    gt = fid.GetGeoTransform()
    proj = fid.GetProjection()
    x_size = fid.RasterXSize
    y_size = fid.RasterYSize
    bands = fid.RasterCount
    lr_x = gt[0] + x_size * gt[1] + y_size * gt[2]
    lr_y = gt[3] + x_size * gt[4] + y_size * gt[5]
    extent = [gt[0], lr_y, lr_x, gt[3]]
    del fid
    center = np.mean([gt[0], lr_x]), np.mean([gt[3], lr_y])
    p = Proj(proj)
    center_geo = p(center[0], center[1], inverse=True)

    return proj, gt, x_size, y_size, extent, center_geo, bands


def save_image(in_array, gt, proj, output_file, no_data_value=np.nan):
    """
    Helper to save a GDAL Cloud Optimized GeoTiff

    Parameters
    ----------
    in_array : 2D array
        Numpy image array
    gt : list of floats
        Output GDAL geotransform
    proj : str
        Output GDAL projection
    output_file : str or Path object
        Path to the output GeoTiff image
    """
    memDriver = gdal.GetDriverByName("MEM")
    if in_array.dtype == bool:
        gdal_type = gdal.GDT_Byte
        no_data_value = None
    elif in_array.dtype == int:
        gdal_type = gdal.GDT_Int32
    else:
        gdal_type = gdal.GDT_Float32

    shape = in_array.shape
    if len(shape) > 2:
        ds = memDriver.Create("MEM", shape[1], shape[0], shape[2], gdal_type)
        ds.SetProjection(proj)
        ds.SetGeoTransform(gt)
        for i in range(shape[2]):
            ds.GetRasterBand(i+1).WriteArray(in_array[:, :, i])

    else:
        ds = memDriver.Create("MEM", shape[1], shape[0], 1, gdal_type)
        ds.SetProjection(proj)
        ds.SetGeoTransform(gt)
        ds.GetRasterBand(1).WriteArray(in_array)
    ds.FlushCache()
    if output_file == "MEM":
        ds.GetRasterBand(1).SetNoDataValue(no_data_value)
        out_ds = ds
    else:
        driver_opt = ['COMPRESS=DEFLATE',
                      'PREDICTOR=YES',
                      'BIGTIFF=IF_SAFER',
                      'NUM_THREADS=ALL_CPUS']
        
        out_ds = gdal.Translate(str(output_file), 
                                ds, 
                                format="COG", 
                                creationOptions=driver_opt,
                                noData=no_data_value, 
                                stats=False)
    # If GDAL driers for other formats do not exist then default to GeoTiff
    if out_ds is None:
        log.warning("Selected GDAL driver is not supported!"
                    "Saving as GeoTiff!")
        driver_opt = ['COMPRESS=DEFLATE',
                      'PREDICTOR=1',
                      'BIGTIFF=IF_SAFER',
                      'NUM_THREADS=ALL_CPUS']

        ds = gdal.Translate(str(output_file), 
                            ds, 
                            format="GTiff", 
                            creationOptions=driver_opt,
                            noData=no_data_value, 
                            stats=True)
        if ds is None:
            raise IOError(f"Image {output_file} could not be created")
    else:
        ds = out_ds

    return ds   
